# 前提知识

## 缓存分类

1. 按缓存位置分类：
   1. 客户端缓存：
      1. 浏览器缓存
      2. 应用缓存
      3. CDN缓存
   2. 服务端缓存
      1. 数据库缓存
      2. 应用层缓存
      3. 分布式缓存
      4. 代理缓存
   3. 网络缓存
      1. DNS缓存
      2. 网关缓存
2. 按缓存内容分类
   1. 静态资源
   2. 动态资源
   3. 全页缓存
   4. 片段缓存
3. 按数据一致性分类
   1. 通读缓存：应用直接读缓存，若缓存未命中，则由缓存从数据源加载
   2. 旁路缓存：应用直接读缓存，若未命中，应用直接加载数据并写入缓存
   3. 写穿透：数据接入时同步更新缓存和数据
   4. 写回：数据先写入缓存，异步更新数据库，性能高但是可能导致丢失数据
4. 按缓存层级分类
   1. 一级缓存
   2. 多级缓存
5. 特殊缓存类型
   1. 持久化缓存，redis
   2. 临时缓存，存在于内容中，进程重启后丢失，Memcached

## 本地缓存与分布式缓存对比

分布式缓存相当于不同节点共同维护同一份缓存数据，

|          | 本地缓存                                                     | 分布式缓存                                                   |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 优点     | 1. 访问速度快<br />2. 开销小，直接存储在内存<br />           | 1. 支持大规模存储<br />2. 数据一致性高<br />3. 持久化存储<br />4. 使用分布式系统 |
| 缺点     | 1.  不同服务器数据一致性<br />2. 缓存大小有限<br />3. 没有持久化存储 | 1. 访问速度慢<br />2. 成本高<br />3. 同步延迟                |
| 适用场景 | 适用于高频小数据存储                                         | 1. 多实例共享内存（微服务）<br />2. 大规模数据缓存<br />3. 多级缓存场景（redis作为mysql缓存） |

## 多级缓存

多级缓存兼顾了本地缓存高性能和分布式缓存一致性。

1. 一级缓存：本地缓存，存储热点数据

2. 二级缓存：主缓存存储(分布式存储)，确保数据一致性和可扩展性

工作流程：

1. 查询本地缓存，未命中查询分布式缓存
2. 查询分布式缓存，未命中查询数据库
3. 查询数据库，获取数据并更新分布式缓存，而后再更新本地缓存

## 缓存置换策略

- FIFO（first in first out）:先进先出
- LRU（Least Recently Used）最近最久未使用，每次访问数据都会放在队头，潜在问题：淘汰热点数据，某一个高频访问的数据在某一段访问频率突然降低。
- LFU（Least Frequently Used） 最近最少使用，记录每个数据的使用频率，选出频率最低进行淘汰
- MRU（Most Recently Used）最近最常使用算法，移除最近最常使用的条目
- ARC（Adaptive Replacement Cache）这个缓存算法同时跟踪记录LFU和LRU，以及驱逐缓存条目，来获得可用缓存的最佳使用.

## ProtoBuf与gRPC

gRPC 默认使用 ProtoBuf 来序列化数据。在 gRPC 中，RPC方法，请求数据，响应数据都是通过 `.proto` 文件来定义的。利用go语言实现ProtoBuf的RPC接口，就能够通过框架实现RPC调用以及结果自动反序列化。

.proto文件编译后会生成两个文件：

```shell
protoc -I ./pb/kama.proto --go_out=./pb --go-grpc_out=./pb --go-grpc_opt=require_unimplemented_servers=false
```

| 文件名                | 作用                                              | 内容                                     |
| --------------------- | ------------------------------------------------- | ---------------------------------------- |
| filename.pb.go      | 定义 Protocol Buffers 消息及其序列化/反序列化逻辑 | 消息类型、枚举、序列化方法等             |
| filename_grpc.pb.go | 定义 gRPC 服务接口及客户端/服务端代码             | 服务接口、客户端调用逻辑、服务端实现框架 |

## etcd

etcd是一个分布式键值存储数据库。主要有以下功能：

1. 键值存储中间件（基本功能）
2. 服务注册与发现（项目使用）
3. 消息发布与订阅
4. 分布式锁

问题背景：分布式环境下，每个节点需要向外提供缓存服务供其他节点调用。RPC通过`IP地址+端口`的方式实现服务发现，但是硬编码IP地址的方式，使得系统灵活性降低。利用自动化的`服务注册与发现`可以实现利用`服务名`实现服务寻址，提高系统可用性和灵活性。

服务注册发现工作流程：该工作模式下可以抽象出三个实体：服务注册中心、服务器、客户端。服务器启动服务时，需要在服务注册中心使用`服务名`注册自己的服务信息。客户端通过向服务注册中心请求`服务名`获取到服务器的IP地址以及端口，根据这些数据调用RPC方法。

# 项目设计

## 缓存组（核心模块）

在分布式缓存系统中，缓存组可以用于将数据分布到不同的节点上。通过将数据按照一定的规则划分到不同的缓存组，然后将这些缓存组分配到不同的服务器节点上，可以实现数据的分布式存储和负载均衡。

### 核心功能

1. 提供缓存的命名空间，管理不同节点的
2. 提供缓存的读取、删除、更新等基本操作。
3. 缓存未命中时，从分布式节点或数据库加载数据并更新分布式缓存。

### 数据获取

1. 缓存状态检查，查询当前缓存组是否活跃
2. 参数验证：确保输入的key不为空
3. 访问本地缓存：尝试从本地缓存读取
4. 统计命中次数：根据情况，更新命中或者未命中次数
5. 分布式缓存中载入数据：本地缓存未命中，尝试从分布式缓存中读取

### 数据加载

当本地缓存不存在数据时，需要利用数据加载从分布式缓存或者数据源获取数据

1. 利用etcd判断需要向哪个节点请求数据
2. 向节点请求数据，成功跳转到5，否则继续
3. 从数据源加载到分布式缓存
4. 加载数据到分布式缓存
5. 统计group命中参数

### 数据设置

1. 缓存状态检查
2. 参数验证
3. 请求来源：本地请求还是远程同步请求
4. 本地更新
5. 如果是本地请求异步同步到其他节点

## 缓存置换策略

### LRU

算法原理：记录每个数据的最近的访问时间，需要替换时，选择最近访问时间最远的数据进行替换。

实现思路：

1. 队列维护最近使用的数据，新访问的数据添加到队列，最久未访问的从队列头弹出
2. 每次访问数据，需要将其添加到队列
3. 队列删除：定期删除、缓存满、插入数据时需要删除队列元素
4. Hash表存储(key->node)：提升遍历效率

### LRU-K （TODO）

算法背景：LRU存在`缓存污染`问题，偶发性的、周期性的批量操作会导致LRU命中率急剧下降。

算法原理：LRU-K维护缓存的访问历史，只有某个缓存访问超过k次，才将其放入内存。缓存满时会淘汰掉在所有帧中反向 k 距离最大的那一帧。`反向 k 距离`的计算方式是当前时间戳与第 k 次先前访问的时间戳之间的时间差。对于历史访问次数少于 k 次的帧，其反向 k 距离被设为正无穷（+inf）。当有多帧都具有正无穷的反向 k 距离时，替换器会淘汰掉时间戳最早的那一帧。

K的长度选取问题：K值增大，命中率会更高，但是适应性差（清除一个缓存需要大量的数据访问，一般选择LRU-2）。

实现方式：

1. 维护两个队列，LRU缓存队列、历史队列。
2. 第一次访问首先放入历史队列，历史队列中访问达到K次，弹出并翻入LRU缓存队列。
3. 历史队列与LRU缓存队列满时候，优先替换时间戳最早的（最早进入队列的）

### LFU（TODO）

算法原理：根据一段时间的访问次数排序，需要替换时候，优先替换访问次数小的。

实现方式：哈希表+双向链表。主流的实现方法，redis基于此实现缓存LFU。

实现方式对比：

| **方案**                | **优点**               | **缺点**        | 适用场景            |
| :---------------------- | :--------------------- | :-------------- | :------------------ |
| **双层哈希表+双向链表** | O(1) 操作，高效        | 实现稍复杂      | 高频读写，严格 O(1) |
| **平衡二叉搜索树**      | 天然有序，支持动态频次 | O(log n) 操作   | 非严格 O(1) 场景    |
| **堆+哈希表**           | 简单易实现             | 更新频次时 O(n) | 低频更新，小数据量  |

### 结构体定义

1. expired过期时间独立存储，不存储到节点信息中。考虑部分缓存并没有生存时间，如果将该属性添加到节点中会导致额外的空间开销。该属性单独设置Map有利于减少空间复杂度。

### 获取缓存项

精细化锁，先通过读锁判断是否存在，再获取写锁，提升并发效率。

1. 使用读锁，如果失败表示过期，需要删除该项
2. 使用写锁，更新LRU队列，二段锁提高效率

### 设置缓存项

1. 输入检查
2. 获取写锁
3. 更新键值(增加键值)
4. 检查是否需要淘汰

### 淘汰策略

1. evict函数和removeElements函数内部没有上锁逻辑，所以调用函数时候必须持有锁
2. 有效期过期、缓存满时需要根据缓存置换策略淘汰缓存

## 缓存并发

缓存并发环境下，主要考虑一些常见问题。项目使用singleFlight单飞机制保证了：针对数据库某个key多次执行load操作，仅仅会向数据库请求一次。

### 缓存击穿

- 定义：某个热点key在缓存中失效，大量请求穿透缓存直达数据库。导致数据库压力陡增
- 解决方法：
  1. 单飞机制（加锁），数据库中一个key仅仅允许一个请求访问。
  2. 缓存不失效/缓存自动续期

### 缓存雪崩

- 定义：缓存中大量数据集中过期。请求洪峰压垮后端系统
- 解决方法：
  1. 过期时间添加随机数
  2. 高可用性：搭建缓存服务集群。redis可以选择哨兵模式或者集群形式
  3. 服务降级：超过一定阈值，停止数据库的查询，所有请求均返回默认值。

### 缓存穿透

- 定义：恶意请求不存在的数据，请求key不在缓存中。
- 解决方法：
  1. 校验参数，过滤恶意请求
  2. 布隆过滤器，利用一个数组实现的哈希表，用于判断请求是否在`数据库`中，依次过滤请求。但是存在误判（Hash碰撞，可以选用新的Hash算法，或者增加Hash轮次缓解）以及数据更新问题（布隆过滤器生成后，数据库信息修改）
  3. 缓存空值，当某个key在数据库不存在时，缓存添加一条数据(key,null)，这样后面的请求直接返回null，不需要查询数据库。

## 一致性哈希

算法背景：分布式缓存架构下，不同的节点存储的缓存不同。客户端需要依据key决定向那个节点请求缓存数据。最简单的思路是利用Hash(key)/nodenumber确定key属于哪个节点.但是存在下述问题：1 节点变更时映射失效 2增加删除节点需要重新计算所有key的hash。一致性Hash通过构建Hash环，使得节点变更时仅仅影响部分缓存数据,进而解决上述问题.

算法原理：使用一个Hash环，节点和key分别Hash，获取值进行排序。key会寻找大于其Hash值的最小节点存储。这样更新节点后，只需要影响到Hash环上相邻的两个位置

数据倾斜问题：大量key集中于少数的节点，使得系统效率降低。

1. 判断是否倾斜？每个节点计算负载程度：
   $$
   节点负载指数=节点请求数量/总请求数量
   $$
   

2. 如果数据节点过少会引发数据倾斜的问题？引入虚拟节点，一个节点对应多个Hash环上的节点

3. key的值过于集中导致的数据倾斜问题？虚拟节点设置策略，设置完虚拟节点后，再次计算每个节点的负载程度，如果超过阈值继续调整。

优化项目：

1. 数据迁移，仅仅调整节点以及虚拟节点会导致调整完，缓存大量丢失，需要一段时间才能恢复。可以考虑引入数据迁移，调整节点位置时迁移数据。

## 缓存服务

缓存服务核心功能在于向外部暴露服务，使得客户端能够通过`网络连接`的方式调用缓存服务。

工作流程：客户端首先通过etcd确定其需要访问的服务器，而后根据etcd提供的网络地址，利用gRPC获取数据。

### 缓存操作接口

### 获取缓存

1. 发送请求：请求包括：group,key
2. 查找缓存组：根据group确定组名
3. 获取缓存值：利用group.Get方法获取值
4. 返回响应：返回key对应的value

### 设置缓存

1. 发送请求
2. 查找缓存组
3. 标记来源：go Context中添加标记，表明set方法来自`用户`还是`对等节点`。如果是对等节点，表明是数据同步请求，则不需要传播（防止无限传播问题）。
4. 获取缓存组
5. 返回响应

## 节点选择器

利用一致性Hash进行节点选择，利用etcd连接到节点。核心功能包括：

1. 动态感知节点加入以及退出
2. 根据缓存需求选择合适节点

### 接口设计：

1. ClientPicker用于选择缓存节点。判断节点是否是本地节点
2. Peer是缓存节点的抽象，封装了缓存节点的操作

### 服务发现与管理

1. 节点初始化阶段，获取所有可用的服务节点
2. 节点运行阶段，持续监听节点并更新

### 节点选择

1. 获取读锁
2. 利用一致性Hash选择节点
3. 查找节点对应的服务

# 项目实现

## 并发编程

1. 公有方法负责获取锁、调用合法性检查，在内部调用私有方法，由私有方法实现处理逻辑。（在调用存在并发的私有方法前一定要获取锁）
2. int64 uint64等统计参数，利用sync/atmoic包转化为原子操作，实现自动并发处理

# 项目测试

## 单元测试

1. LFU单元测试

## 整体测试

### 1. 安装

```bash
go get github.com/youngyangyang04/KamaCache-Go
```

### 2. 启动 etcd
```bash
# 使用 Docker 启动 etcd
docker run -d --name etcd_lq \
  -p 2379:2379 \
  quay.io/coreos/etcd:v3.5.0 \
  etcd --advertise-client-urls http://0.0.0.0:2379 \
  --listen-client-urls http://0.0.0.0:2379
```

### 3. 运行实例

详情见测试 demo：[example/test.go](example/test.go)


### 4. 多节点部署
```bash
# 启动节点 A
go run example/test.go -port 8001 -node A

# 启动节点 B
go run example/test.go -port 8002 -node B

# 启动节点 C
go run example/test.go -port 8003 -node C
```

### 5. 测试结果

A 进程：

```bash
go run example/test.go -port 8001 -node A  
2025/04/08 10:16:36 [节点A] 启动，地址: :8001
INFO[0000] Created cache group [test] with cacheBytes=2097152, expiration=0s 
INFO[0000] [KamaCache] registered peers for group [test] 
2025/04/08 10:16:36 [节点A] 等待节点注册...
2025/04/08 10:16:36 [节点A] 开始启动服务...
INFO[0000] Server starting at :8001                     
INFO[0000] Service registered: kama-cache at 172.22.152.216:8001 
INFO[0000] Successfully created client for 172.22.152.216:8001 
INFO[0000] New service discovered at 172.22.152.216:8001 
INFO[0002] Successfully created client for 172.22.152.216:8002 
INFO[0002] New service discovered at 172.22.152.216:8002 

=== 节点A：设置本地数据 ===
INFO[0005] Cache initialized with type lru2, max bytes: 2097152 
节点A: 设置键 key_A 成功
2025/04/08 10:16:41 [节点A] 等待其他节点准备就绪...
INFO[0005] grpc set request resp: value:"这是节点A的数据"      
INFO[0006] Successfully created client for 172.22.152.216:8003 
INFO[0006] New service discovered at 172.22.152.216:8003 
2025/04/08 10:17:11 当前已发现的节点:
2025/04/08 10:17:11 - 172.22.152.216:8002
2025/04/08 10:17:11 - 172.22.152.216:8003
2025/04/08 10:17:11 - 172.22.152.216:8001

=== 节点A：获取本地数据 ===
直接查询本地缓存...
缓存统计: map[cache_closed:false cache_hit_rate:0 cache_hits:0 cache_initialized:true cache_misses:0 cache_size:2 closed:false expiration:0s loader_errors:0 loader_hits:0 loads:0 local_hits:0 local_misses:0 name:test peets:0 peer_misses:0]
项目有效，将其移至二级缓存
节点A: 获取本地键 key_A 成功: 这是节点A的数据

=== 节点A：尝试获取远程数据 key_B ===
2025/04/08 10:17:11 [节点A] 开始查找键 key_B 的远程节点
项目有效，将其移至二级缓存
节点A: 获取远程键 key_B 成功: 这是节点B的数据

=== 节点A：尝试获取远程数据 key_C ===
2025/04/08 10:17:11 [节点A] 开始查找键 key_C 的远程节点
节点A: 获取远程键 key_C 成功: 这是节点C的数据
```

B 进程：

```bash
go run example/test.go -port 8002 -node B
2025/04/08 10:16:39 [节点B] 启动，地址: :8002
INFO[0000] Successfully created client for 172.22.152.216:8001 
INFO[0000] Discovered service at 172.22.152.216:8001    
INFO[0000] Created cache group [test] with cacheBytes=2097152, expiration=0s 
INFO[0000] [KamaCache] registered peers for group [test] 
2025/04/08 10:16:39 [节点B] 等待节点注册...
2025/04/08 10:16:39 [节点B] 开始启动服务...
INFO[0000] Server starting at :8002                     
INFO[0000] Service registered: kama-cache at 172.22.152.216:8002 
INFO[0000] Successfully created client for 172.22.152.216:8002 
INFO[0000] New service discovered at 172.22.152.216:8002 
INFO[0003] Successfully created client for 172.22.152.216:8003 
INFO[0003] New service discovered at 172.22.152.216:8003 

=== 节点B：设置本地数据 ===
INFO[0005] Cache initialized with type lru2, max bytes: 2097152 
节点B: 设置键 key_B 成功
2025/04/08 10:16:44 [节点B] 等待其他节点准备就绪...
INFO[0005] grpc set request resp: value:"这是节点B的数据"      
项目有效，将其移至二级缓存
2025/04/08 10:17:14 当前已发现的节点:
2025/04/08 10:17:14 - 172.22.152.216:8001
2025/04/08 10:17:14 - 172.22.152.216:8002
2025/04/08 10:17:14 - 172.22.152.216:8003

=== 节点B：获取本地数据 ===
直接查询本地缓存...
缓存统计: map[cache_closed:false cache_hit_rate:1 cache_hits:1 cache_initialized:true cache_misses:0 cache_size:2 closed:false expiration:0s hit_rate:1 loader_errors:0 loader_hits:0 loads:0 local_hits:1 local_misses:0 naest peer_hits:0 peer_misses:0]
项目有效，将其移至二级缓存
节点B: 获取本地键 key_B 成功: 这是节点B的数据

=== 节点B：尝试获取远程数据 key_A ===
2025/04/08 10:17:14 [节点B] 开始查找键 key_A 的远程节点
节点B: 获取远程键 key_A 成功: 这是节点A的数据

=== 节点B：尝试获取远程数据 key_C ===
2025/04/08 10:17:14 [节点B] 开始查找键 key_C 的远程节点
节点B: 获取远程键 key_C 成功: 这是节点C的数据
```

C 进程：

```bash
go run example/test.go -port 8003 -node C
2025/04/08 10:16:42 [节点C] 启动，地址: :8003
INFO[0000] Successfully created client for 172.22.152.216:8001 
INFO[0000] Discovered service at 172.22.152.216:8001    
INFO[0000] Successfully created client for 172.22.152.216:8002 
INFO[0000] Discovered service at 172.22.152.216:8002    
INFO[0000] Created cache group [test] with cacheBytes=2097152, expiration=0s 
INFO[0000] [KamaCache] registered peers for group [test] 
2025/04/08 10:16:42 [节点C] 等待节点注册...
2025/04/08 10:16:42 [节点C] 开始启动服务...
INFO[0000] Server starting at :8003                     
INFO[0000] Service registered: kama-cache at 172.22.152.216:8003 
INFO[0000] Successfully created client for 172.22.152.216:8003 
INFO[0000] New service discovered at 172.22.152.216:8003 

=== 节点C：设置本地数据 ===
INFO[0005] Cache initialized with type lru2, max bytes: 2097152 
节点C: 设置键 key_C 成功
2025/04/08 10:16:47 [节点C] 等待其他节点准备就绪...
INFO[0005] grpc set request resp: value:"这是节点C的数据"      
2025/04/08 10:17:17 当前已发现的节点:
2025/04/08 10:17:17 - 172.22.152.216:8001
2025/04/08 10:17:17 - 172.22.152.216:8002
2025/04/08 10:17:17 - 172.22.152.216:8003

=== 节点C：获取本地数据 ===
直接查询本地缓存...
缓存统计: map[cache_closed:false cache_hit_rate:0 cache_hits:0 cache_initialized:true cache_misses:0 cache_size:1 closed:false expiration:0s loader_errors:0 loader_hits:0 loads:0 local_hits:0 local_misses:0 name:test peets:0 peer_misses:0]
项目有效，将其移至二级缓存
节点C: 获取本地键 key_C 成功: 这是节点C的数据

=== 节点C：尝试获取远程数据 key_A ===
2025/04/08 10:17:17 [节点C] 开始查找键 key_A 的远程节点
节点C: 获取远程键 key_A 成功: 这是节点A的数据

=== 节点C：尝试获取远程数据 key_B ===
2025/04/08 10:17:17 [节点C] 开始查找键 key_B 的远程节点
节点C: 获取远程键 key_B 成功: 这是节点B的数据
```

# 参考文献

项目文档：[学习建议](https://www.yuque.com/chengxuyuancarl/wk9epc/lowygouc8r64fwt4)，文档密码：bo4v

项目代码：[代码仓库](https://github.com/cigulingjing/kamacache)
